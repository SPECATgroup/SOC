
Slurm Job Summary
*****************
- General information:
    date = Fr 2. Feb 13:28:26 CET 2024
    hostname = nesh-clk352
- Job information:
    JobId = 10362556
    JobName = H2Te_orca
    UserId = suphc355(743340)
    Account = suphc355
    QOS = normal
    NodeList = nesh-clk352
    Features = (null)
    Command = /gxfs_work/cau/suphc355/homologes/H2X/orca/Te/run.sh
    WorkDir = /gxfs_work/cau/suphc355/homologes/H2X/orca/Te
    StdOut = /gxfs_work/cau/suphc355/homologes/H2X/orca/Te/ba.out
    StdErr = /gxfs_work/cau/suphc355/homologes/H2X/orca/Te/ba.err
- Requested resources:
    Timelimit = 00:10:00 ( 600s )
    MinMemoryNode = 32G ( 32768.000M )
    NumNodes = 1
    NumCPUs = 1
    NumTasks = 1
    CPUs/Task = 1
- Used resources:
    RunTime = 00:01:01 ( 61s )
    MaxRSS = 71876K ( 70.191M )
====================
- Important conclusions and remarks:
    * !!! Please, always check if the number of requested cores and nodes matches the need of your program/code !!!
    * !!! Less than 20% of requested walltime used !!! Consider adaptation of your batch script.
    * !!! Less than 10% of requested main memory used !!! Consider adaptation of your batch script.

