
Slurm Job Summary
*****************
- General information:
    date = Mi 6. Dez 15:11:35 CET 2023
    hostname = nesh-srp142
- Job information:
    JobId = 10198608
    JobName = ae_bench
    UserId = suphc355(743340)
    Account = suphc355
    QOS = normal
    NodeList = nesh-srp[142-145]
    Features = (null)
    Command = /gxfs_work/cau/suphc355/benchmark_pbe0/pbe0_bm_ae/pyranthion/run.sh
    WorkDir = /gxfs_work/cau/suphc355/benchmark_pbe0/pbe0_bm_ae/pyranthion
    StdOut = /gxfs_work/cau/suphc355/benchmark_pbe0/pbe0_bm_ae/pyranthion/ba.out
    StdErr = /gxfs_work/cau/suphc355/benchmark_pbe0/pbe0_bm_ae/pyranthion/ba.err
- Requested resources:
    Timelimit = 2-00:00:00 ( 172800s )
    MinMemoryNode = 160G ( 163840.000M )
    NumNodes = 4
    NumCPUs = 128
    NumTasks = 64
    CPUs/Task = 2
- Used resources:
    RunTime = 01:03:55 ( 3835s )
    MaxRSS = 7160K ( 6.992M )
====================
- Important conclusions and remarks:
    * !!! Please, always check if the number of requested cores and nodes matches the need of your program/code !!!
    * !!! Less than 10% of requested walltime used !!! Consider adaptation of your batch script.
    * !!! Less than 10% of requested main memory used !!! Consider adaptation of your batch script.

