
Slurm Job Summary
*****************
- General information:
    date = Wed Oct 18 20:19:27 CEST 2023
    hostname = neshcl136
- Job information:
    JobId = 8876575
    JobName = iso
    UserId = suphc355(743340)
    Account = suphc355
    Partition = cluster
    QOS = normal
    NodeList = neshcl[136,157-159,292,349-351]
    Features = (null)
    Command = /gxfs_work1/cau/suphc355/benchmark_pbe0/pbe0_bm_tm/trip/isoalloxazin/run.sh
    WorkDir = /gxfs_work1/cau/suphc355/benchmark_pbe0/pbe0_bm_tm/trip/isoalloxazin
    StdOut = /gxfs_work1/cau/suphc355/benchmark_pbe0/pbe0_bm_tm/trip/isoalloxazin/batch.out
    StdErr = /gxfs_work1/cau/suphc355/benchmark_pbe0/pbe0_bm_tm/trip/isoalloxazin/batch.err
- Requested resources:
    Timelimit = 04:00:00 ( 14400s )
    MinMemoryNode = 32G ( 32768.000M )
    NumNodes = 8
    NumCPUs = 256
    NumTasks = 128
    CPUs/Task = 2
    TresPerNode = 
- Used resources:
    RunTime = 01:59:53 ( 7193s )
    MaxRSS = 274972K ( 268.527M )
====================
- Important conclusions and remarks:
    * !!! Please, always check if the number of requested cores and nodes matches the need of your program/code !!!
    * !!! Less than 50% of requested walltime used !!! Please, adapt your batch script.
    * !!! Less than 10% of requested main memory used !!! Please, adapt your batch script.

